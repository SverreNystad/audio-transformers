{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2ef7fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluate in /home/svernys/Documents/projects/audio/venv/lib/python3.11/site-packages (0.4.3)\n",
      "Collecting jiwer\n",
      "  Downloading jiwer-3.1.0-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /home/svernys/Documents/projects/audio/venv/lib/python3.11/site-packages (from evaluate) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/svernys/Documents/projects/audio/venv/lib/python3.11/site-packages (from evaluate) (2.2.6)\n",
      "Requirement already satisfied: dill in /home/svernys/Documents/projects/audio/venv/lib/python3.11/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/svernys/Documents/projects/audio/venv/lib/python3.11/site-packages (from evaluate) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/svernys/Documents/projects/audio/venv/lib/python3.11/site-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/svernys/Documents/projects/audio/venv/lib/python3.11/site-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /home/svernys/Documents/projects/audio/venv/lib/python3.11/site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /home/svernys/Documents/projects/audio/venv/lib/python3.11/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /home/svernys/Documents/projects/audio/venv/lib/python3.11/site-packages (from evaluate) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /home/svernys/Documents/projects/audio/venv/lib/python3.11/site-packages (from evaluate) (0.32.3)\n",
      "Requirement already satisfied: packaging in /home/svernys/Documents/projects/audio/venv/lib/python3.11/site-packages (from evaluate) (25.0)\n",
      "Requirement already satisfied: click>=8.1.8 in /home/svernys/Documents/projects/audio/venv/lib/python3.11/site-packages (from jiwer) (8.2.1)\n",
      "Collecting rapidfuzz>=3.9.7\n",
      "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/svernys/Documents/projects/audio/venv/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/svernys/Documents/projects/audio/venv/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (20.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/svernys/Documents/projects/audio/venv/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/svernys/Documents/projects/audio/venv/lib/python3.11/site-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.7)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/svernys/Documents/projects/audio/venv/lib/python3.11/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/svernys/Documents/projects/audio/venv/lib/python3.11/site-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/svernys/Documents/projects/audio/venv/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/svernys/Documents/projects/audio/venv/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/svernys/Documents/projects/audio/venv/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/svernys/Documents/projects/audio/venv/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (2025.4.26)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/svernys/Documents/projects/audio/venv/lib/python3.11/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/svernys/Documents/projects/audio/venv/lib/python3.11/site-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/svernys/Documents/projects/audio/venv/lib/python3.11/site-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/svernys/Documents/projects/audio/venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/svernys/Documents/projects/audio/venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/svernys/Documents/projects/audio/venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/svernys/Documents/projects/audio/venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/svernys/Documents/projects/audio/venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/svernys/Documents/projects/audio/venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/svernys/Documents/projects/audio/venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/svernys/Documents/projects/audio/venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Installing collected packages: rapidfuzz, jiwer\n",
      "Successfully installed jiwer-3.1.0 rapidfuzz-3.13.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install evaluate jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1742700",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference = \"This is a test sentence.\"\n",
    "prediction = \"This is test sentenceWrong.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01a8e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from evaluate import load\n",
    "\n",
    "wer_metric = load(\"wer\")\n",
    "\n",
    "wer = wer_metric.compute(references=[reference], predictions=[prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1271e29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Error Rate (WER): 0.400 (lower is better)\n",
      "Accuracy: 0.600 (higher is better)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Word Error Rate (WER): {wer:.3f} (lower is better)\")\n",
    "print(f\"Accuracy: {1 - wer:.3f} (higher is better)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb6ad9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "\n",
    "cer_metric = load(\"cer\")\n",
    "\n",
    "cer = cer_metric.compute(references=[reference], predictions=[prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a06ff9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character Error Rate (WER): 0.292 (lower is better)\n",
      "Accuracy: 0.708 (higher is better)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Character Error Rate (WER): {cer:.3f} (lower is better)\")\n",
    "print(f\"Accuracy: {1 - cer:.3f} (higher is better)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7799a77",
   "metadata": {},
   "source": [
    "CER is much more forgiving then WER, as small errors in the transcription are not penalized as much. This is because CER is based on character-level accuracy, while WER is based on word-level accuracy. In many cases, a small error in a word can lead to a large increase in WER, while the same error may only slightly affect CER.\n",
    "\n",
    "However most of the time CER is not used. This is because that CER only looks at the characters in the transcription, and does not take into account the meaning of the words. Like grammar. We want to encourage the model to gain a better understanding of the language, and not just the characters. This is why WER is more commonly used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c89343",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "When one normalizes a dataset for ASR one remove any casing and the ppunctionation. This makes the Speech Recognition task easier, as the model does not have to learn to recognize different cases and punctuation marks. Like the difference between \"Hello\" and \"hello\", or \"Hello,\" and \"Hello\". This has actually been shown to dramatically improve the performance of ASR models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7da91ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' he tells us that at this festive season of the year with christmas and roast beef looming before us similarly is drawn from eating and its results occur most readily to the mind '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers.models.whisper.english_normalizer import BasicTextNormalizer\n",
    "\n",
    "normalizer = BasicTextNormalizer()\n",
    "\n",
    "prediction = \" He tells us that at this festive season of the year, with Christmas and roast beef looming before us, similarly is drawn from eating and its results occur most readily to the mind.\"\n",
    "normalized_prediction = normalizer(prediction)\n",
    "\n",
    "normalized_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c945f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03488372093023256"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference = \"HE TELLS US THAT AT THIS FESTIVE SEASON OF THE YEAR WITH CHRISTMAS AND ROAST BEEF LOOMING BEFORE US SIMILES DRAWN FROM EATING AND ITS RESULTS OCCUR MOST READILY TO THE MIND\"\n",
    "normalized_referece = normalizer(reference)\n",
    "\n",
    "wer = wer_metric.compute(\n",
    "    references=[normalized_referece], predictions=[normalized_prediction]\n",
    ")\n",
    "wer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c84187",
   "metadata": {},
   "source": [
    "## Fine-tuning ASR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ed9c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "    torch_dtype = torch.float16\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    torch_dtype = torch.float32\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=\"openai/whisper-small\",\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b17deb7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26d65887e83b4a1da83305d332b6c6ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e76e0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "common_voice_test = load_dataset(\n",
    "    \"mozilla-foundation/common_voice_13_0\", \"dv\", split=\"test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a8aa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "\n",
    "all_predictions = []\n",
    "\n",
    "# run streamed inference\n",
    "for prediction in tqdm(\n",
    "    pipe(\n",
    "        KeyDataset(common_voice_test, \"audio\"),\n",
    "        max_new_tokens=128,\n",
    "        generate_kwargs={\"task\": \"transcribe\"},\n",
    "        batch_size=32,\n",
    "    ),\n",
    "    total=len(common_voice_test),\n",
    "):\n",
    "    all_predictions.append(prediction[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d930b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "\n",
    "wer_metric = load(\"wer\")\n",
    "\n",
    "wer_ortho = 100 * wer_metric.compute(\n",
    "    references=common_voice_test[\"sentence\"], predictions=all_predictions\n",
    ")\n",
    "wer_ortho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe8b428",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.whisper.english_normalizer import BasicTextNormalizer\n",
    "\n",
    "normalizer = BasicTextNormalizer()\n",
    "\n",
    "# compute normalised WER\n",
    "all_predictions_norm = [normalizer(pred) for pred in all_predictions]\n",
    "all_references_norm = [normalizer(label) for label in common_voice_test[\"sentence\"]]\n",
    "\n",
    "# filtering step to only evaluate the samples that correspond to non-zero references\n",
    "all_predictions_norm = [\n",
    "    all_predictions_norm[i]\n",
    "    for i in range(len(all_predictions_norm))\n",
    "    if len(all_references_norm[i]) > 0\n",
    "]\n",
    "all_references_norm = [\n",
    "    all_references_norm[i]\n",
    "    for i in range(len(all_references_norm))\n",
    "    if len(all_references_norm[i]) > 0\n",
    "]\n",
    "\n",
    "wer = 100 * wer_metric.compute(\n",
    "    references=all_references_norm, predictions=all_predictions_norm\n",
    ")\n",
    "\n",
    "wer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
